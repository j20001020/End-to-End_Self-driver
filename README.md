# End-to-End\_Self-driver

本專案為一個以深度學習實作自駕車控制的專案。透過 CNN 模型訓練影像與控制訊號的對應關係，並與 AirSim 模擬器整合，達成基本的自駕車轉向控制。

## 專案簡介

本專案包含兩個主要部分：

1. **模型訓練 (`Train_model.py`)**：

   * 使用 CNN 模型訓練來自影像的轉向控制分類任務。
   * 輸入為影像，輸出為 21 類的轉向角分類。
   * 資料從 CSV 中讀取，包含圖像檔名與標註的轉向角類別。
   * 訓練完成後會儲存模型為 `car_model.h5`。

2. **模擬器控制 (`Connect_Airsim.py`)**：

   * 使用訓練好的模型連接至 AirSim 模擬器，進行即時的圖像預測與車輛控制。
   * 從模擬器擷取影像後輸入模型，輸出對應的轉向控制指令，並套用至車輛。

## 環境需求

* Python 3.x
* TensorFlow / Keras
* OpenCV
* NumPy
* AirSim 模擬器與 Python API

## 使用方式

1. 準備訓練資料與對應的標註 CSV。
2. 執行 `Train_model.py` 以訓練模型並儲存至 `car_model.h5`。
3. 確保 AirSim 模擬器正在執行並啟動車輛模擬場景。
4. 執行 `Connect_Airsim.py`，自駕控制將根據模型輸出自動進行。

## 備註

* 此專案為學術用途練習，並未進行完整的誤差分析與實車測試。
* 模型僅依據簡化場景與有限資料訓練，不適用於實際道路。

